{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import thu vien YOLO\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#Load model\n",
    "model = YOLO(\"../Model/Models_yolov10n_dataBienSoNhieuLoaiv4_datanoscale_anhmau1nhan/runs/detect/train/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.79  Python-3.9.19 torch-2.4.0+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "Setup complete  (8 CPUs, 7.8 GB RAM, 148.9/229.5 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n",
      "2.4.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# phai bat buoc cai goi C/C++ development cua visual studio\n",
    "# Kiem tra torch va CUDA co phu hop?\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # Kiểm tra xem CUDA có khả dụng không\n",
    "print(torch.cuda.device_count())   # Số lượng GPU có sẵn\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Kiem tra torch ket noi GPU\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\envs\\car_detection\\lib\\site-packages\\torch\\cuda\\__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m     )\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "#Kiem tra torch ket noi GPU\n",
    "import torch\n",
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Làm xám ảnh\n",
    "import cv2\n",
    "\n",
    "def convert_to_grayscale(image_path, max_width=800, max_height=800):\n",
    "    # Đọc bức ảnh từ đường dẫn\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Kiểm tra nếu ảnh không tồn tại hoặc không thể đọc\n",
    "    if image is None:\n",
    "        print(\"Không thể đọc ảnh. Vui lòng kiểm tra đường dẫn.\")\n",
    "        return None\n",
    "    \n",
    "    # Chuyển ảnh sang dạng grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Lấy kích thước ban đầu của ảnh\n",
    "    original_height, original_width = gray_image.shape[:2]\n",
    "\n",
    "    # Tính toán tỷ lệ để resize ảnh sao cho không vượt quá kích thước tối đa\n",
    "    scaling_factor = min(max_width / original_width, max_height / original_height, 1)\n",
    "\n",
    "    # Resize ảnh nếu cần\n",
    "    if scaling_factor < 1:\n",
    "        new_width = int(original_width * scaling_factor)\n",
    "        new_height = int(original_height * scaling_factor)\n",
    "        gray_image = cv2.resize(gray_image, (new_width, new_height))\n",
    "    \n",
    "    # Trả về ảnh xám đã được resize\n",
    "    return gray_image\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "gray_img = convert_to_grayscale(\"../Predict_Data/1.jpg\")\n",
    "#gray_img = convert_to_grayscale(\"./predict_data/z3945403596223_a1e193a942d30367b0b0bee724439713.jpg\")\n",
    "# Hiển thị ảnh xám nếu có\n",
    "if gray_img is not None:\n",
    "    cv2.imshow(\"Gray Image\", gray_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../image/xemay/thanh-nien-dung-tren-yen-xe-may-dang-chay.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#### Xử lý ảnh nếu là tệp ảnh\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_image:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# Đọc ảnh\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Thực hiện inference YOLOv8\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     results \u001b[38;5;241m=\u001b[39m model(frame)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\envs\\car_detection\\lib\\site-packages\\ultralytics\\utils\\patches.py:26\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR):\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    Read an image from a file.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m        (np.ndarray): The read image.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mimdecode(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m, flags)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../image/xemay/thanh-nien-dung-tren-yen-xe-may-dang-chay.jpg'"
     ]
    }
   ],
   "source": [
    "######### Detect và lấy ra các detected frame để lưu lại thành hình ảnh\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "#### Load the YOLOv8 model\n",
    "#model = YOLO(\"./Models_4_yolov8n_datav5/runs/detect/train/weights/best.pt\")\n",
    "#model = YOLO(\"./Models_5_yolov10n/runs/detect/train/weights/best.pt\")\n",
    "#model = YOLO(\"./Models_6_yolov10n_datav7/runs/detect/train/weights/best.pt\")\n",
    "# model = YOLO(\"../ThamKhao_Project/Computervisionprojects-main/ANPR_YOLOv10/weights/best.pt\")\n",
    "#model = YOLO(\"./Models_yolov10n_dataBienSoNhieuLoaiv1/runs/detect/train/weights/best.pt\")\n",
    "#model = YOLO(\"./Models_yolov10n_dataBienSoNhieuLoaiv4_datanoscale_anhmau1nhan/runs/detect/train/weights/best.pt\")\n",
    "\n",
    "#### Open the video file\n",
    "#video_path = \"./predict_data/VID_20220519_144812.mp4\"\n",
    "#video_path = \"./predict_data/VID_20230506_163430.mp4\"\n",
    "#video_path = \"./predict_data/101.jpg\"\n",
    "#video_path = \"./predict_data/Video xe máy - xe hơi chạy trên đường.mp4\"\n",
    "#video_path = \"./predict_data/video_1.gif\"\n",
    "#video_path = \"./predict_data/VID_20220519_144619.mp4\"\n",
    "#video_path = \"./predict_data/bike_counter_10min.mp4\"\n",
    "# video_path = \"./predict_data/VID_20230506_163430.mp4\"\n",
    "video_path = \"../../image/xemay/thanh-nien-dung-tren-yen-xe-may-dang-chay.jpg\"\n",
    "\n",
    "#video_path = \"./predict_data/xe_2.jpg\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "#### Tạo thư mục để lưu các frame nếu chưa có\n",
    "output_folder = \"./detected_frames\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "frame_count = 0\n",
    "confidence_threshold = 0 # Mức độ tin cậy cho trước\n",
    "\n",
    "#### Kiểm tra xem tệp là ảnh hay video\n",
    "is_image = video_path.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "\n",
    "#### Định nghĩa màu sắc cho từng nhãn\n",
    "colors = {\n",
    "    \"bienso_do\": (0, 0, 255),       # Màu đỏ cho biển quân sự\n",
    "    \"bienso_vang\": (0, 255, 255),       # Màu vàng đậm cho biển vàng\n",
    "    \"bienso_xanh\": (255, 255, 128),     # Màu xanh nhạt cho biển xanh\n",
    "    \"bienso\": (0, 255, 0)               # Màu xanh lá cho biển thường\n",
    "}\n",
    "\n",
    "#### Xử lý ảnh nếu là tệp ảnh\n",
    "if is_image:\n",
    "    # Đọc ảnh\n",
    "    frame = cv2.imread(video_path)\n",
    "    \n",
    "    # Thực hiện inference YOLOv8\n",
    "    results = model(frame)\n",
    "    \n",
    "    # Kiểm tra nếu có bất kỳ đối tượng nào được phát hiện\n",
    "    if len(results[0].boxes) > 0:\n",
    "        for box in results[0].boxes:\n",
    "            confidence = box.conf[0]\n",
    "            label = box.cls  # Chỉ số nhãn lớp\n",
    "            label_name = model.names[int(label)]  # Tên nhãn\n",
    "\n",
    "            # Kiểm tra nếu độ tin cậy trên ngưỡng\n",
    "            if confidence > confidence_threshold:\n",
    "                # Lấy tọa độ bounding box\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "\n",
    "                # Cắt phần ảnh phát hiện\n",
    "                detected_object = frame[y1:y2, x1:x2]\n",
    "\n",
    "                # Lưu ảnh đã cắt kèm tên nhãn và độ tin cậy trong tên file\n",
    "                frame_filename = os.path.join(output_folder, f\"{label_name}_{confidence:.2f}_frame_{frame_count:04d}.jpg\")\n",
    "                cv2.imwrite(frame_filename, detected_object)\n",
    "\n",
    "                # Xác định màu sắc dựa trên tên nhãn\n",
    "                color = colors.get(label_name, (255, 255, 255))\n",
    "\n",
    "                # Vẽ bounding box\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Hiển thị nhãn và độ tin cậy\n",
    "                text = f\"{label_name} {confidence:.2f}\"\n",
    "                cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "        # Hiển thị kết quả xử lý ảnh\n",
    "        cv2.imshow(\"YOLOv10 Detection on Image\", frame)\n",
    "        cv2.waitKey(0)  # Nhấn phím bất kỳ để đóng cửa sổ hiển thị\n",
    "\n",
    "else:\n",
    "    #### Mở video và xử lý từng frame nếu là video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Thực hiện inference YOLOv8\n",
    "            results = model(frame)\n",
    "\n",
    "            # Kiểm tra nếu có bất kỳ đối tượng nào được phát hiện\n",
    "            if len(results[0].boxes) > 0:\n",
    "                for box in results[0].boxes:\n",
    "                    confidence = box.conf[0]\n",
    "                    label = box.cls\n",
    "                    label_name = model.names[int(label)]\n",
    "\n",
    "                    # Kiểm tra nếu độ tin cậy trên ngưỡng\n",
    "                    if confidence > confidence_threshold:\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "                        detected_object = frame[y1:y2, x1:x2]\n",
    "                        frame_filename = os.path.join(output_folder, f\"{label_name}_{confidence:.2f}_frame_{frame_count:04d}.jpg\")\n",
    "                        cv2.imwrite(frame_filename, detected_object)\n",
    "                        color = colors.get(label_name, (255, 255, 255))\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                        text = f\"{label_name} {confidence:.2f}\"\n",
    "                        cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "                cv2.imshow(\"YOLOv10 Inference on Video\", frame)\n",
    "                frame_count += 1\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "print(cv2.getBuildInformation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lưu 5001 frame vào thư mục 'detected_frames'\n"
     ]
    }
   ],
   "source": [
    "# Cắt tất cả thành hình ảnh\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Đường dẫn tới video\n",
    "video_path = './predict_data/bike_counter_10min.mp4'  # Thay đổi đường dẫn tới video của bạn\n",
    "video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "\n",
    "# Tạo thư mục lưu frame nếu chưa có\n",
    "output_folder = 'detected_frames'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Đọc video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_count = 0\n",
    "saved_frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Lấy mỗi 3 frame\n",
    "    if frame_count % 3 == 0:\n",
    "        frame_filename = f\"{video_name}_frame_{saved_frame_count}.jpg\"\n",
    "        frame_path = os.path.join(output_folder, frame_filename)\n",
    "        \n",
    "        # Lưu frame\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        saved_frame_count += 1\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Giải phóng video\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Lưu {saved_frame_count} frame vào thư mục '{output_folder}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.100, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Car_License_Plates-2 to yolov8:: 100%|██████████| 32912/32912 [00:14<00:00, 2241.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Car_License_Plates-2 in yolov8:: 100%|██████████| 1436/1436 [00:00<00:00, 2582.75it/s]\n"
     ]
    }
   ],
   "source": [
    "#!pip install roboflow\n",
    "\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"HTzRcoTwwe0y2jQf0bvN\")\n",
    "# project = rf.workspace(\"labelimgbiensoxe\").project(\"biensoxe_all-zrwrj\")\n",
    "# version = project.version(8)\n",
    "# dataset = version.download(\"yolov8\")\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"8joVH7TL2k5V6uScFBEy\")\n",
    "project = rf.workspace(\"moin\").project(\"car_license_plates\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov8\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 bien_so_quansu, 1 bien_so_xanh, 54.6ms\n",
      "Speed: 5.0ms preprocess, 54.6ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model YOLO\n",
    "#model = YOLO(\"./Models_yolov10n_dataBienSoNhieuLoaiv1/runs/detect/train/weights/last.pt\")  \n",
    "model = YOLO(\"./Models_yolov10n_dataBienSoNhieuLoaiv2/runs/detect/train/weights/last.pt\")\n",
    "\n",
    "# Đường dẫn đầu vào cho ảnh hoặc video\n",
    "input_path = \"./predict_data/anh_anhsuutam_24.jpg\"  # Thay bằng đường dẫn tới ảnh hoặc video của bạn\n",
    "\n",
    "output_folder = \"./detected_frames\"\n",
    "os.makedirs(output_folder, exist_ok=True)  # Tạo thư mục nếu chưa tồn tại\n",
    "\n",
    "# Kiểm tra xem input là ảnh hay video\n",
    "is_image = input_path.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "\n",
    "# Ngưỡng độ tin cậy cho việc hiển thị và lưu đối tượng\n",
    "confidence_threshold = 0.5  # Thay đổi theo nhu cầu\n",
    "\n",
    "if is_image:\n",
    "    # Nếu là ảnh, đọc và xử lý ảnh\n",
    "    image = cv2.imread(input_path)\n",
    "    results = model(image)\n",
    "\n",
    "    # Xử lý từng đối tượng được phát hiện\n",
    "    for box in results[0].boxes:\n",
    "        confidence = box.conf[0]\n",
    "        if confidence >= confidence_threshold:\n",
    "            label = box.cls\n",
    "            label_name = model.names[int(label)]\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "\n",
    "            # Cắt và lưu đối tượng được phát hiện\n",
    "            detected_object = image[y1:y2, x1:x2]\n",
    "            output_filename = f\"{label_name}_{confidence:.2f}.jpg\"\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            cv2.imwrite(output_path, detected_object)\n",
    "\n",
    "            # Vẽ bounding box và nhãn lên ảnh gốc\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(image, f\"{label_name} {confidence:.2f}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # Hiển thị ảnh đã annotate\n",
    "    cv2.imshow(\"Detected Objects\", image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "else:\n",
    "    # Nếu là video, đọc và xử lý từng frame\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        results = model(frame)\n",
    "        for box in results[0].boxes:\n",
    "            confidence = box.conf[0]\n",
    "            if confidence >= confidence_threshold:\n",
    "                label = box.cls\n",
    "                label_name = model.names[int(label)]\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "\n",
    "                # Cắt và lưu đối tượng được phát hiện\n",
    "                detected_object = frame[y1:y2, x1:x2]\n",
    "                output_filename = f\"{label_name}_{confidence:.2f}_frame_{frame_count:04d}.jpg\"\n",
    "                output_path = os.path.join(output_folder, output_filename)\n",
    "                cv2.imwrite(output_path, detected_object)\n",
    "\n",
    "                # Vẽ bounding box và nhãn lên frame\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"{label_name} {confidence:.2f}\", (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        # Hiển thị frame đã annotate\n",
    "        cv2.imshow(\"Detected Objects\", frame)\n",
    "        frame_count += 1\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Đóng cửa sổ hiển thị\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
